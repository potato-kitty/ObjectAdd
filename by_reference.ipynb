{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Tuple, List, Callable, Dict\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch.nn.functional as nnf\n",
    "import numpy as np\n",
    "import abc\n",
    "import ptp_utils\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from attention_controller import *\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import diffusers\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from skimage import morphology\n",
    "\n",
    "print(\"diffusers:\",diffusers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MY_TOKEN = ''\n",
    "LOW_RESOURCE = False\n",
    "NUM_DIFFUSION_STEPS = 50\n",
    "GUIDANCE_SCALE = 7.5\n",
    "MAX_NUM_WORDS = 77\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "your_SD_model_path = ''\n",
    "ldm_stable = StableDiffusionPipeline.from_pretrained(your_SD_model_path, use_auth_token=MY_TOKEN).to(device)\n",
    "tokenizer = ldm_stable.tokenizer\n",
    "your_out_folder_path = ''\n",
    "output_folder = your_out_folder_path\n",
    "if not os.path.exists(output_folder):\n",
    "    os.mkdir(output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_and_display(prompts, controller, if_process = False, in_img = None, full_img = None,if_save = False, latent=None, run_baseline=False, generator=None,sqr_replace=False,switch = False, bbox = None,img_name = None , output_folder = None, box = None):\n",
    "    images, x_t = ptp_utils.text2image_ldm_stable(ldm_stable, prompts, controller, real_img=in_img, full_img = full_img, latent=latent, num_inference_steps=NUM_DIFFUSION_STEPS, guidance_scale=GUIDANCE_SCALE, generator=generator, low_resource=LOW_RESOURCE,is_switch=switch,bboxes=bbox)\n",
    "    ptp_utils.view_images(images,if_save, img_name = img_name, output_folder=output_folder,box=box)\n",
    "    return images, x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "g_cpu = torch.Generator().manual_seed(8888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_images(images, if_save = False, num_rows=1, offset_ratio=0.02,output_folder = None, save_which = -1, img_name = None, box = None):\n",
    "    if type(images) is list:\n",
    "        num_empty = len(images) % num_rows\n",
    "    elif images.ndim == 4:\n",
    "        num_empty = images.shape[0] % num_rows\n",
    "    else:\n",
    "        images = [images]\n",
    "        num_empty = 0\n",
    "\n",
    "    empty_images = np.ones(images[0].shape, dtype=np.uint8) * 255\n",
    "    images = [image.astype(np.uint8) for image in images] + [empty_images] * num_empty\n",
    "    num_items = len(images)\n",
    "\n",
    "    h, w, c = images[0].shape\n",
    "    offset = int(h * offset_ratio)\n",
    "    num_cols = num_items // num_rows\n",
    "    image_ = np.ones((h * num_rows + offset * (num_rows - 1),\n",
    "                      w * num_cols + offset * (num_cols - 1), 3), dtype=np.uint8) * 255\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            image_[i * (h + offset): i * (h + offset) + h:, j * (w + offset): j * (w + offset) + w] = images[\n",
    "                i * num_cols + j]\n",
    "\n",
    "    if if_save:\n",
    "        out_img = images[save_which]\n",
    "        if box is not None:\n",
    "            the_box = box[0]\n",
    "            out_img = Image.fromarray(out_img)\n",
    "            a = ImageDraw.ImageDraw(out_img)\n",
    "            for sub_box in the_box:\n",
    "                print('sub_box: ',sub_box)\n",
    "                a.rectangle(((sub_box[0], sub_box[1]), (sub_box[2], sub_box[3])), fill=None, outline='blue', width=2)\n",
    "            out_img.save(output_folder + img_name + \" Rec.jpg\")\n",
    "        else:\n",
    "            im = Image.fromarray(out_img)\n",
    "            im.save(output_folder + img_name + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ours Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_img = None\n",
    "full_msk = None\n",
    "real_img_full = None\n",
    "g_cpu = torch.Generator().manual_seed(8888)\n",
    "\n",
    "out_path_name = './TPAMI_exp_out'\n",
    "in_path = './mask_info/'\n",
    "\n",
    "out_path_list = [out_path_name + \"_no_process/\",out_path_name + \"_edit/\",out_path_name + \"_ref/\"]\n",
    "\n",
    "for path in out_path_list:\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "file_list = os.listdir(in_path)\n",
    "img_namelist = os.listdir(out_path_list[1])\n",
    "\n",
    "or_file =  open(\"./prompt_original.txt\",\"r\")\n",
    "lines = or_file.read().splitlines()\n",
    "\n",
    "for idx, filename in enumerate(lines):\n",
    "\n",
    "    '''\n",
    "    if filename + '.jpg' in img_namelist:\n",
    "        continue\n",
    "    '''\n",
    "    prompts = [\"\",\"\",\"\"]\n",
    "    with open(in_path + filename + '.txt', \"r\") as f:\n",
    "        contents = f.readlines()\n",
    "    \n",
    "    x1 = int(contents[0].strip('\\n'))\n",
    "    y1 = int(contents[1].strip('\\n'))\n",
    "    w = int(contents[2].strip('\\n'))\n",
    "    h = int(contents[3].strip('\\n'))\n",
    "    prompts[-1] = contents[-1].strip('\\n')\n",
    "\n",
    "    if 'no' in prompts[-1] or 'No' in prompts[-1]:\n",
    "        _ = ptp_utils.init_latent(None, ldm_stable, 512, 512, g_cpu, 3)\n",
    "        continue\n",
    "\n",
    "    prompts[0] = filename\n",
    "\n",
    "    tmp_w = w\n",
    "    w = h\n",
    "    h = tmp_w\n",
    "\n",
    "    tmp_x1 = x1\n",
    "    x1 = y1\n",
    "    y1 = tmp_x1\n",
    "\n",
    "    size_re = w\n",
    "    if w < h:\n",
    "        size_re = h\n",
    "\n",
    "\n",
    "    alpha_idx = 0\n",
    "\n",
    "    if h < w*alpha_idx:\n",
    "        h = int(w*alpha_idx)\n",
    "    elif w < h*alpha_idx:\n",
    "        w = int(h*alpha_idx)\n",
    "\n",
    "    x2 = x1 + w - 1 \n",
    "    y2 = y1 + h - 1\n",
    "\n",
    "    att_mask = np.zeros((512,512))\n",
    "\n",
    "    for i in range(x1,x2+1):\n",
    "        for j in range(y1,y2+1):\n",
    "            att_mask[j,i] = 1\n",
    "\n",
    "    beta_idx = 0.1\n",
    "\n",
    "    x1_r = max(x1/att_mask.shape[0],beta_idx)\n",
    "    y1_r = max(y1/att_mask.shape[1],beta_idx)\n",
    "    x2_r = max(x2/att_mask.shape[0],beta_idx)\n",
    "    y2_r = max(y2/att_mask.shape[1],beta_idx)\n",
    "\n",
    "    box = [[[x1_r,y1_r,x2_r,y2_r]]]\n",
    "\n",
    "    controller = AttentionReplace(prompts, NUM_DIFFUSION_STEPS, cross_replace_steps=.4, self_replace_steps=0.4, where_change = 1,mask = att_mask, full_mask = full_msk)\n",
    "\n",
    "\n",
    "    iamges,_ = run_and_display(prompts, controller, latent=None,  bbox = box, generator=g_cpu)\n",
    "\n",
    "    for i,path in enumerate(out_path_list):\n",
    "        view_images(iamges,if_save=True,output_folder=path,save_which=i,img_name=filename)\n",
    "\n",
    "    print(str(idx+1)+\"/\"+str(len(file_list)),\"done!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
